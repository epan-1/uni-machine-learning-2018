{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Import the SKLearn library\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "# Q1a\n",
    "# print(iris.DESCR)\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1b\n",
    "# Create x for as an array defining the attribute values.\n",
    "# Create y as the array defining the 'gold-standard'/groud \n",
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    }
   ],
   "source": [
    "# Q1c, confirming that x is a 2 dimensional array\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333331"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2a. Building a 0-R classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "zero_r = DummyClassifier(strategy='most_frequent')\n",
    "zero_r.fit(x,y)\n",
    "zero_r.predict(x)\n",
    "# This classifier has chosen class 0, i.e. 'setosa'\n",
    "\n",
    "# Q2b. Getting the evaluation metric for the 0-R classifier\n",
    "zero_r.score(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2b).\n",
    "This is known as the \"training accuracy\" and is frowned upon since\n",
    "it is essentially giving the classifier the answers beforehand and then\n",
    "asking it to remember the answers. Pretty useless in terms of achieving the \n",
    "goals of machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-R score: 0.333333333333\n",
      "Weight Score: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Q2c.\n",
    "weighted_classifier = DummyClassifier(strategy='stratified')\n",
    "weighted_classifier.fit(x,y)\n",
    "weighted_classifier.predict(x)\n",
    "\n",
    "# Comparing the scores\n",
    "zero_score = zero_r.score(x,y)\n",
    "print('0-R score: ' + str(zero_score))\n",
    "weight_score = 0\n",
    "for i in range(10):\n",
    "    weight_score += weighted_classifier.score(x,y)\n",
    "print('Weight Score: ' + str(weight_score/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2c). On average it has the about the same accuracy as 0-R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-R Acc: 0.666666666667\n",
      "DT Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Q3a.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "one_r = DecisionTreeClassifier(max_depth=1)\n",
    "one_r.fit(x,y)\n",
    "dt = DecisionTreeClassifier(max_depth=None)\n",
    "dt.fit(x,y)\n",
    "print('1-R Acc: ' + str(one_r.score(x,y)))\n",
    "print('DT Acc: ' + str(dt.score(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Q3b.\n",
    "print(one_r.feature_importances_)\n",
    "# The sepal length attribute is being used to classify the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q3c.\n",
    "# Skip this one for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3d). It's actually Gini index and is like entropy in which it measures how heterogeneous/mixed/distributed a value is over some set. It is similar mathematically to information gain since they are both a weighted sum of something. Only the actual formulas are slightly different. As such the behaviour should not vary much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Acc: 1.0\n",
      "Entropy Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Q3d.\n",
    "# For gini index\n",
    "dt_g = DecisionTreeClassifier(max_depth=None, criterion='gini')\n",
    "dt_g.fit(x,y)\n",
    "dt_e = DecisionTreeClassifier(max_depth=None, criterion='entropy')\n",
    "dt_e.fit(x,y)\n",
    "\n",
    "print('Gini Acc: ' + str(dt_g.score(x,y)))\n",
    "print('Entropy Acc: ' + str(dt_e.score(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O-R Acc: 0.348214285714\n",
      "1-R Acc: 0.678571428571\n",
      "DT Acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Q4a.\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training the classifiers\n",
    "zero_r.fit(x_train, y_train)\n",
    "one_r.fit(x_train, y_train)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "print('O-R Acc: ' + str(accuracy_score(zero_r.predict(x_train), y_train)))\n",
    "print('1-R Acc: ' + str(accuracy_score(one_r.predict(x_train), y_train)))\n",
    "print('DT Acc: ' + str(accuracy_score(dt.predict(x_train), y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4a). The accuracies don't differ much. This might be because we are still giving the classifiers the same data to check and classify even though its only a smaller subset of the original dataset they were apart of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O-R Acc: 0.289473684211\n",
      "1-R Acc: 0.631578947368\n",
      "DT Acc: 0.894736842105\n"
     ]
    }
   ],
   "source": [
    "#Q4b.\n",
    "\n",
    "# Training the classifiers \n",
    "zero_r.fit(x_train, y_train)\n",
    "one_r.fit(x_train, y_train)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "print('O-R Acc: ' + str(accuracy_score(zero_r.predict(x_test), y_test)))\n",
    "print('1-R Acc: ' + str(accuracy_score(one_r.predict(x_test), y_test)))\n",
    "print('DT Acc: ' + str(accuracy_score(dt.predict(x_test), y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4b). Now all of the classifiers obtain lower accuracies.  \n",
    "- For 0-R the accuracy is distorted most likely due to the fact that the test set having a wider range of different classes when compared to the majority\n",
    "- For 1-R the accuracy is less most likely due to the fact that the test set has more different classes for the attribute being checked\n",
    "- Decision tree is going down as due to the same reason as 1-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O-R Acc: 0.318584070796\n",
      "1-R Acc: 0.654867256637\n",
      "DT Acc: 0.964601769912\n"
     ]
    }
   ],
   "source": [
    "# Q4c.\n",
    "\n",
    "# Modifying the percentage of the dataset to use as training set and testing set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.75)\n",
    "\n",
    "# Training the classifiers \n",
    "zero_r.fit(x_train, y_train)\n",
    "one_r.fit(x_train, y_train)\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "print('O-R Acc: ' + str(accuracy_score(zero_r.predict(x_test), y_test)))\n",
    "print('1-R Acc: ' + str(accuracy_score(one_r.predict(x_test), y_test)))\n",
    "print('DT Acc: ' + str(accuracy_score(dt.predict(x_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333333333333\n",
      "0.666666666667\n",
      "0.953333333333\n"
     ]
    }
   ],
   "source": [
    "# Q5a.\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(zero_r, x, y, cv=10)\n",
    "\n",
    "def ave_cross_val_score(classifier, x, y, n):\n",
    "    sum = 0\n",
    "    scores = cross_val_score(classifier, x, y, cv=n)\n",
    "    for i in range(n):\n",
    "        sum += scores[i]\n",
    "    return sum/n\n",
    "    \n",
    "print(ave_cross_val_score(zero_r, x, y, 10))\n",
    "print(ave_cross_val_score(one_r, x, y, 10))\n",
    "print(ave_cross_val_score(dt, x, y, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5b). The accuracies are roughly the same compared to all of the other training accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
