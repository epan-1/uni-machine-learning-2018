{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import text datasets from scikit learn\n",
    "# Q1a). and Q1b).\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Newsgroups to access\n",
    "categories = ['alt.atheism','talk.religion.misc']\n",
    "# Get the train subset of \n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "shuffle=True, random_state=30027)\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "shuffle=True, random_state=30027)\n",
    "X_train = data_train.data\n",
    "y_train = data_train.target\n",
    "X_test = data_test.data\n",
    "y_test = data_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1c\n",
    "It is not possible to determine the class from inspecting the text alone especially using human eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2a). & Q2b).\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectoriser = CountVectorizer()\n",
    "X_train_cv = vectoriser.fit_transform(X_train)\n",
    "X_test_cv = vectoriser.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents is: 857\n",
      "Number of unique words is: 18089\n",
      "Documents is: 570\n",
      "Number of unique words is: 18089\n"
     ]
    }
   ],
   "source": [
    "# Q2c).\n",
    "print(\"Documents is: \" + str(np.shape(X_train_cv)[0]) + \"\\n\" + \"Number of unique words is: \" + str(np.shape(X_train_cv)[1]))\n",
    "print(\"Documents is: \" + str(np.shape(X_test_cv)[0]) + \"\\n\" + \"Number of unique words is: \" + str(np.shape(X_test_cv)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2d).\n",
    "No there are no documents in X_test whose values are all 0  \n",
    "Also there is no way a document would have values which are all 0 unless a prespecified vocabulary of words\n",
    "is given to the vectoriser. Since a document with values that are all 0 means that the document contains all \n",
    "new unique words that were not present in the a-priori dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "x2 = SelectKBest(chi2, k=10)\n",
    "x2.fit(X_train_cv, y_train)\n",
    "# these two statements can be combined into\n",
    "X_train = x2.transform(X_train_cv) # a single statement via fit_transform()\n",
    "X_test = x2.transform(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For X_train: (857, 10)\n",
      "For X_test: (570, 10)\n"
     ]
    }
   ],
   "source": [
    "# Q3a).\n",
    "print(\"For X_train: \" + str(np.shape(X_train)))\n",
    "print(\"For X_test: \" + str(np.shape(X_test)))\n",
    "\n",
    "# So the shape of the 2 sets remain the same in terms of the number of samples (i.e. documents) but the number of \n",
    "# features that they have (i.e. The unique words) has been reduced to the top 10 according to the scoring of\n",
    "# Chi-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atheism\n",
      "atheist\n",
      "atheists\n",
      "brian\n",
      "caltech\n",
      "christ\n",
      "islamic\n",
      "jesus\n",
      "keith\n",
      "ra\n"
     ]
    }
   ],
   "source": [
    "# Q3b).\n",
    "for feat_num in x2.get_support(indices=True):\n",
    "    print(vectoriser.get_feature_names()[feat_num])\n",
    "    \n",
    "# Looks kinda right since we have selected documents relating to religion. But it does seem like it relates to the bias in Chi-Squared. \n",
    "# In the context of these documents, it seems that the top 10 best features appear to be random numbers that rarely appear throughout \n",
    "# all of the documents sampled but will always frequently appear with the same given class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allan\n",
      "atheism\n",
      "atheists\n",
      "caltech\n",
      "cco\n",
      "it\n",
      "keith\n",
      "of\n",
      "schneider\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# Q3c).\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mi = SelectKBest(mutual_info_classif, k=10)\n",
    "mi.fit(X_train_cv,y_train)\n",
    "X_train = mi.transform(X_train_cv)\n",
    "X_test = mi.transform(X_test_cv)\n",
    "\n",
    "# Print out top 10 features calculated by MI\n",
    "for feat_num in mi.get_support(indices=True):\n",
    "    print(vectoriser.get_feature_names()[feat_num])\n",
    "    \n",
    "# This one would seem more intuitive as MI would bias features that appear commonly but may not be informative\n",
    "# as to which class they actually refer to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4a). Building a classifier of the text using K-NN and possibly NB or Decision trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
