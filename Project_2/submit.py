###
# This Python file contains the code for the implementation of 3 learners used
# to predict the age of a blog author given their blog posts.
# Code written by: Edmond Pan
# Student Num: 841389
###

import re
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, \
    precision_score, recall_score
import itertools
import numpy as np
import matplotlib.pyplot as plt

import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_selection import SelectKBest, chi2
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier

# ---------------------------------------------------------------------------- #

# HELPER FUNCTION DEFINITIONS

def pre_process(data):
    """
    The function will do the following to the data.
        - Force all characters to be lower case
        - Remove any non-alphanumeric characters from the string.
    :param data: Data is a string representing the blog post
    :return: Another string representing the pre-processed data
    """
    # Uses regex '\W+' to remove any character that is not alphabetical or a
    # number.
    output = ''
    for word in data.split(' '):
        if word != '' and word[0].isalnum():
            output += ' ' + re.sub('[\W_]+', '', word.lower(), flags=re.UNICODE)
    return output


def convert_age(raw):
    """
    This function takes the age class and puts it into the specified range given
    by the
    :param raw: A string containing the self-identified age of the blog author
    :return: Returns the corresponding range that the age is in or ? if it
             does not fit into any of the ranges. Inclusive ranges are as follows:
                - 14-16
                - 24-26
                - 34-36
                - 44-46
    """
    if raw == '?':
        # If it's already a question mark skip it
        return '?'
    else:
        if 14 <= int(raw) <= 16:
            return '14-16'
        elif 24 <= int(raw) <= 26:
            return '24-26'
        elif 34 <= int(raw) <= 36:
            return '34-36'
        elif 44 <= int(raw) <= 46:
            return '44-46'
        else:
            return '?'


def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.get_cmap('Wistia')):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    :param cm: This is the confusion matrix generated by sklearn
    :param classes: This refers to a list of all the possible classes
    :param normalize: If set to true, the counts will be normalised with respect
                      to the total number of samples
    :param title: A string to give the title of the plot
    :param cmap: The colors to give the different parts of the confusion matrix
    """
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')


def produce_metrics(learner, X, y, learner_name):
    """
    This function takes a learner implemented from the sklearn library and
    prints out the corresponding metrics for the given instances and true
    class labels:
        - Accuracy score
        - F1-Score which is a more specific version of F-Score where beta=1
        - Precision
        - Recall
        - Confusion matrix
    :param learner: A learner object from the sklearn library
    :param X: An array-like object containing the instances of a given dataset
              to be used for evaluation of the learner
    :param y: The ground truth labels for the corresponding instances in X
    :param learner_name: A string to identify the name of the learner when p
                         printing out metrics
    :return: None
    """
    predictions = learner.predict(X)
    class_names = ['14-16', '24-26', '34-36', '44-46', '?']
    acc_score = accuracy_score(y, predictions)
    f1_val = f1_score(y, predictions, labels=class_names, average='weighted')
    prec = precision_score(y, predictions, labels=class_names, average='weighted')
    rec = recall_score(y, predictions, labels=class_names, average='weighted')
    conf_matrix = confusion_matrix(y, predictions, labels=class_names)

    print("Accuracy score of {} = {}".format(learner_name, acc_score))
    print("F1 score of {} = {}".format(learner_name, f1_val))
    print("Precision score of {} = {}".format(learner_name, prec))
    print("Recall score of {} = {}".format(learner_name, rec))
    plt.figure()
    plot_confusion_matrix(conf_matrix, class_names,
                          title='Confusion Matrix for {}'.format(learner_name))
    plt.show()

    return

# ---------------------------------------------------------------------------- #

# Processing script that pre-processes all raw data files into the desired
# format
# Read in the data taking only the age column and text column


file_path = 'COMP30027_2018S1_proj2-data/'
train_name = 'train_raw.csv'
dev_name = 'dev_raw.csv'
test_name = 'test_raw.csv'
train_output = 'train_processed.csv'
dev_output = 'dev_processed.csv'
test_output = 'test_processed.csv'

train_data = pd.read_csv(file_path + train_name, header=None, usecols=(2, 6),
                         encoding='ISO-8859-1')
dev_data = pd.read_csv(file_path + dev_name, header=None, usecols=(2, 6),
                       encoding='ISO-8859-1')
test_data = pd.read_csv(file_path + test_name, header=None, usecols=(2, 6),
                        encoding='ISO-8859-1')

# Apply the appropriate pre-processing function to the text and age columns
# of all the sets
train_data[6] = train_data[6].apply(pre_process)
train_data[2] = train_data[2].apply(convert_age)

dev_data[6] = dev_data[6].apply(pre_process)
dev_data[2] = dev_data[2].apply(convert_age)

test_data[6] = test_data[6].apply(pre_process)
test_data[2] = test_data[2].apply(convert_age)

# Write out the processed dataframes to their corresponding csv files
train_data.to_csv(file_path + train_output, columns=(6,2), index=False)
dev_data.to_csv(file_path + dev_output, columns=(6,2), index=False)
test_data.to_csv(file_path + test_output, columns=(6,2), index=False)

# The files that were written out will have the blog post in column 1 and age
# in column 2.

# ---------------------------------------------------------------------------- #

# MAIN SCRIPT THAT RUNS EACH OF THE LEARNERS ON THE DATA SETS

# Read in the data
file_path = 'COMP30027_2018S1_proj2-data/'
file_name = 'train_processed.csv'
train = pd.read_csv(file_path + file_name, header=None, skiprows=1,
                    skipinitialspace=True, encoding='ISO-8859-1')
dev = pd.read_csv(file_path + 'dev_processed.csv', header=None, skiprows=1,
                  skipinitialspace=True, encoding='ISO-8859-1')

top10_train = pd.read_csv(file_path + 'train_top10.csv', header=None,
                          encoding='ISO-8859-1')
top10_dev = pd.read_csv(file_path + 'dev_top10.csv', header=None,
                        encoding='ISO-8859-1')

test = pd.read_csv(file_path + 'test_processed.csv', header=None, skiprows=1,
                   skipinitialspace=True, encoding='ISO-8859-1')

# # Fill in nan values with a single whitespace
train = train.fillna(value=' ')
dev = dev.fillna(value=' ')
test = test.fillna(value=' ')

# Get X and y out of the data
X_train = train[0].tolist()
X_dev = dev[0].tolist()
X_test = test[0].tolist()


y_train = np.array(train[1].tolist())
y_dev = np.array(dev[1].tolist())

print("Extracting features... (Please wait)")

# Create and fit a CountVectoriser
# vectoriser = CountVectorizer(ngram_range=(1, 3))
# X_train_cv = vectoriser.fit_transform(X_train)
# X_dev_cv = vectoriser.transform(X_dev)
# X_test_cv = vectoriser.transform(X_test)


# Create and fit a TFIDF Vectoriser
vectoriser = CountVectorizer(ngram_range=(1, 3))
X_train_cv = vectoriser.fit_transform(X_train)
X_dev_cv = vectoriser.transform(X_dev)
X_test_cv = vectoriser.transform(X_test)

# Select k Best features via chi-squared
# x2 = SelectKBest(chi2, k=50000)
# x2.fit(X_train_cv, y_train)
# X_train_x2 = x2.transform(X_train_cv)
# X_dev_x2 = x2.transform(X_dev_cv)

print("Commence classifier training...")

# Using Naive Bayes
nb = MultinomialNB(alpha=0.5)
# nb.fit(X_train_cv, y_train)
# produce_metrics(nb, X_dev_cv, y_dev, 'Multinomial Naive Bayes')

# Using SVMs (This has the best parameters for voting classifier)
C = 0.1
lsv = LinearSVC(C=C)

# Using Logistic regression (This is the optimal performance)
lr = LogisticRegression(C=1, solver='sag', max_iter=100)
# lr.fit(X_train_cv, y_train)
# produce_metrics(lr, X_dev_cv, y_dev, 'Logistic Regression')


voter = VotingClassifier(estimators=[('lr', lr), ('lsv', lsv), ('nb', nb)], voting='hard')
voter.fit(X_train_cv, y_train)
produce_metrics(voter, X_dev_cv, y_dev, 'Voter')


print("Producing predictions...")

# Producing the predictions
with open(file_path + 'predictions.csv', 'w+') as out:
    out.write('Id,Prediction\n')
    # Get the predictions
    predictions = lr.predict(X_test_cv)
    instance_id = 1
    for predict in predictions:
        line = ''
        line += '3' + str(instance_id) + ',' + predict + '\n'
        out.write(line)
        instance_id += 1
