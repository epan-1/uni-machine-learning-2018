{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Q1a). Loading in the data\n",
    "# The actual attributes\n",
    "X = []\n",
    "# The class labels\n",
    "y = []\n",
    "f = open('car_data.csv', 'r')\n",
    "for line in f:\n",
    "    atts = line[:-1].split(\",\")\n",
    "    X.append(atts[:-1])\n",
    "    y.append(atts[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances is: 1728\n",
      "Number of attributes is: 6\n"
     ]
    }
   ],
   "source": [
    "# Q1b).\n",
    "print(\"Number of instances is: \" + str(len(X)))\n",
    "print(\"Number of attributes is: \" + str(len(X[0])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1b. Cont.\n",
    "From https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.names, we can tell that all of the attributes are of nominal type. There are 4 possible values that the class can take.\n",
    "\n",
    "### Q1c.\n",
    "There are no missing values in the dataset. After looking at the dataset I cannot find any evidence that would suggest this dataset has been artificially created. However, reading the metadata associated with this dataset suggests that it was created from a hierarchical decision model. The dataset was then used to demonstrate a system called DEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1d).\n",
    "# Import scikit learn to build a simple decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=None)\n",
    "# dt.fit(X,y)\n",
    "    \n",
    "# Attempting to build any classifier from scikit learn will not work. A type error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a).\n",
    "\n",
    "def convert_class(raw):\n",
    "    \"\"\"\n",
    "    Function converts a list of class names into integers for the car dataset\n",
    "    \"\"\"\n",
    "    if raw==\"unacc\": \n",
    "        return 0\n",
    "    elif raw==\"acc\": \n",
    "        return 1\n",
    "    elif raw==\"good\": \n",
    "        return 2\n",
    "    elif raw==\"vgood\": \n",
    "        return 3\n",
    "    \n",
    "def convert_buying_maint(raw):\n",
    "    \"\"\"\n",
    "    Function converts into integers the first 2 attributes of the car dataset. buying and maintenance.\n",
    "    \"\"\"\n",
    "    if raw==\"vhigh\": \n",
    "        return 0\n",
    "    elif raw==\"high\": \n",
    "        return 1\n",
    "    elif raw==\"med\": \n",
    "        return 2\n",
    "    elif raw==\"low\": \n",
    "        return 3 \n",
    "    \n",
    "def convert_doors(raw):\n",
    "    if raw==\"2\": \n",
    "        return 0\n",
    "    elif raw==\"3\": \n",
    "        return 1\n",
    "    elif raw==\"4\": \n",
    "        return 2\n",
    "    elif raw==\"5more\": \n",
    "        return 3  \n",
    "    \n",
    "def convert_persons(raw):\n",
    "    if raw==\"2\": \n",
    "        return 0\n",
    "    elif raw==\"4\": \n",
    "        return 1\n",
    "    elif raw==\"more\": \n",
    "        return 2\n",
    "    \n",
    "def convert_lug_boot(raw):\n",
    "    if raw==\"small\": \n",
    "        return 0\n",
    "    elif raw==\"med\": \n",
    "        return 1\n",
    "    elif raw==\"big\": \n",
    "        return 2\n",
    "\n",
    "def convert_safety(raw):\n",
    "    if raw==\"low\": \n",
    "        return 0\n",
    "    elif raw==\"med\": \n",
    "        return 1\n",
    "    elif raw==\"high\": \n",
    "        return 2\n",
    "\n",
    "# Q2b).\n",
    "# Now to convert the data\n",
    "X_new = []\n",
    "y_new = []\n",
    "for row in X:\n",
    "    new_row = []\n",
    "    # Convert each attribute and add it\n",
    "    new_row.append(convert_buying_maint(row[0]))\n",
    "    new_row.append(convert_buying_maint(row[1]))\n",
    "    new_row.append(convert_doors(row[2]))\n",
    "    new_row.append(convert_persons(row[3]))\n",
    "    new_row.append(convert_lug_boot(row[4]))\n",
    "    new_row.append(convert_safety(row[5]))\n",
    "    X_new.append(new_row)\n",
    "    \n",
    "for val in y:\n",
    "    y_new.append(convert_class(val))\n",
    "\n",
    "# a = np.array(X)\n",
    "# print(np.unique(a.transpose()[0]))\n",
    "# print(np.unique(a.transpose()[1]))\n",
    "# print(np.unique(a.transpose()[2]))\n",
    "# print(np.unique(a.transpose()[3]))\n",
    "# print(np.unique(a.transpose()[4]))\n",
    "# print(np.unique(a.transpose()[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2c). Split the data up\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_new,y_new, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB acc: 0.7141203703703703\n",
      "GNB acc: 0.6886574074074074\n",
      "BNB acc: 0.8472222222222222\n"
     ]
    }
   ],
   "source": [
    "# Q3).\n",
    "# The most appropriate would be the multinomial Naive Bayes since we have non-binary, discrete attributes.\n",
    "\n",
    "# Q3a).\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(x_train, y_train)\n",
    "print(\"MNB acc: \" + str(accuracy_score(mnb.predict(x_test), y_test)))\n",
    "\n",
    "# Q3b).\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "print(\"GNB acc: \" + str(accuracy_score(gnb.predict(x_test), y_test)))\n",
    "\n",
    "bnb = BernoulliNB(alpha=5)\n",
    "bnb.fit(x_train, y_train)\n",
    "print(\"BNB acc: \" + str(accuracy_score(bnb.predict(x_test), y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3c.\n",
    "Turning smoothing off resulted in little to no change in the accuracies. With a slight increase for the Bernoulli Naive Bayes. I don't know what the significance of the reported accuracy is.\n",
    "\n",
    "### Q3d.\n",
    "Nothing seems to be happening to the accuracy even when increasing the smoothing parameter to really high values. I have no idea what is happening and I wish he provided some answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
